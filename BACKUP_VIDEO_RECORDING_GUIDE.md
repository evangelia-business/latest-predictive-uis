# Backup Demo Video Recording Instructions

## üé• Recording Plan: Two Complete Demo Flows

**Purpose:** Show contextual suggestions adapt to different topics (proves it's real AI, not hardcoded)

**Total Recording Time:** ~12 minutes (2 demos √ó 5 min + 2 min buffer)

---

## üìã Pre-Recording Setup

### Before You Start Recording:

```bash
# 1. Start Ollama (if using)
ollama serve
ollama list  # Verify llama3.2 is available

# 2. Start dev server
npm run dev

# 3. Open browser
open http://localhost:3001
```

### Browser Setup:
- [ ] Zoom to 150% (Cmd/Ctrl + Plus several times)
- [ ] Full screen mode (F11) or hide bookmarks
- [ ] Open DevTools (F12)
- [ ] Position: Network tab visible on right, Console tab ready
- [ ] Clear console logs
- [ ] Close unnecessary tabs

### Screen Recording:
- [ ] Use QuickTime (Mac) or OBS (Windows/Mac)
- [ ] Record entire screen or browser window only
- [ ] **Start recording BEFORE you begin Demo 1**

---

## üé¨ Demo 1: Frontend/AI Topic (5 min)

### Part 1: Ask Question (90 sec)

**Type this question:**
```
"What are the key differences between React and Vue?"
```
OR
```
"What should I know about machine learning basics?"
```

**As you type & click Ask, narrate:**
> "I'm going to ask about [React vs Vue / ML basics]... watch what happens."

**As thinking appears:**
> "Notice the thinking panel appearing... these are REAL AI thoughts streaming in progressively from Ollama."

**Point to thoughts appearing one by one**

**When final answer + suggestions appear:**
> "And here's the final answer, plus 4 contextually-related suggestions generated by the AI."

---

### Part 2: Show Prefetching (60 sec)

**Open DevTools ‚Üí Network tab:**
> "Let me show you what just happened in the background..."

**Point to EventSource connections:**
> "See these 2 new EventSource connections? The app automatically started prefetching the TOP 2 suggestions by confidence score."

**Switch to Console tab:**
> "The console shows: 'Prefetching top 2 by confidence' - not all 4, just the top 2. That's smart prefetching."

**Wait 5-10 seconds for prefetch to complete**

---

### Part 3: Click Prefetched Suggestion (30 sec)

**Click one of the TOP 2 suggestions:**
> "Now when I click one of the top suggestions..."

**Instant result appears with ‚ö° badge:**
> "BOOM! Instant result - less than 100 milliseconds. The lightning bolt badge shows it came from cache."

**Point to Console:**
> "Console confirms: 'Cache hit' - this was prefetched in the background."

---

### Part 4: Show Caching (30 sec)

**Type the EXACT same question from Part 1:**
> "Let me ask the same question again... [type exact question]"

**Click Ask:**
> "And click Ask..."

**Instant result:**
> "Instant again! No API call, no waiting. Same question, zero wait time. That's the caching layer."

---

### Part 5: Recap (30 sec)

> "So in one flow, we saw all 3 techniques:"
> "1. Streaming - progressive AI thoughts"
> "2. Smart prefetching - top 2 by confidence automatically loaded"
> "3. Caching - instant replay for repeated questions"
>
> "Now let me show you this works for ANY topic - not just tech questions."

**Refresh the page**

---

## üèñÔ∏è Demo 2: Greek Islands Topic (5 min)

### Part 1: Ask Question (90 sec)

**Type this question:**
```
"What are the best Greek islands to visit in summer?"
```
OR
```
"What should I know before traveling to Greece?"
```

**As you type:**
> "Completely different topic now - travel instead of tech. Let's see if the suggestions adapt..."

**As thinking appears:**
> "Same streaming pattern - AI thinking progressively..."

**When suggestions appear:**
> "And look - the 4 suggestions are NOW COMPLETELY DIFFERENT. They're contextually related to Greek travel, not tech. This proves the AI is generating suggestions based on the conversation, not using hardcoded responses."

**Point to suggestions - read a couple aloud to emphasize they're travel-related**

---

### Part 2: Show Prefetching (60 sec)

**Open DevTools ‚Üí Network tab:**
> "Same pattern - 2 new EventSource connections for the top 2 suggestions."

**Console shows prefetching:**
> "Top 2 by confidence are being prefetched right now."

---

### Part 3: Click Prefetched Suggestion (30 sec)

**Click one of the TOP 2 suggestions:**
> "Click a top suggestion..."

**Instant result:**
> "Instant! Prefetched in the background while I was reading the first answer."

---

### Part 4: Show the Difference (60 sec)

> "So we just saw the same system adapt to two completely different topics:"
>
> "First demo: React/ML ‚Üí Suggestions were about frameworks, programming concepts"
>
> "Second demo: Greek islands ‚Üí Suggestions were about travel, beaches, culture"
>
> "This is REAL AI - Ollama llama3.2 - generating contextual suggestions on the fly, not hardcoded responses."

---

### Part 5: Final Recap (30 sec)

> "All 3 predictive UI techniques working together:"
> "1. Streaming - engaging, not anxious waiting"
> "2. Smart prefetching - top 2 by confidence score"
> "3. Caching - instant repeated queries"
>
> "Result: 67% reduction in perceived wait time."
>
> "And it works for ANY domain - tech, travel, health, finance - whatever your application needs."

**Stop recording**

---

## üíæ After Recording

### Edit (Optional):
- Trim dead space at start/end
- Can speed up prefetch waiting (5-10 sec ‚Üí 2 sec)
- Add title card: "Backup Recording - Live Demo"

### Export:
- Save as **MP4** (best compatibility)
- Name: `predictive-ui-demo-backup.mp4`
- Resolution: 1080p minimum

### Test:
- [ ] Play full video
- [ ] Verify DevTools are visible
- [ ] Verify console logs are readable
- [ ] Audio narration is clear (if recorded with audio)

---

## üéØ Using the Backup During Your Talk

### When to Use:
- WiFi fails
- Ollama crashes
- Browser issues
- Dev server won't start
- Projector compatibility issues

### How to Use:
1. Say: "Let me show you a recording of this in action..."
2. Play video (muted or with your live narration over it)
3. Pause at key moments to point things out
4. Resume narration matching the video

### Pro Tip:
If playing silent video, narrate live as if it's happening real-time:
- "Watch the thinking panel appear..."
- "Now the suggestions are loading..."
- "And... instant result!"

---

## üìù Quick Reference: Two Demo Questions

| Demo | Question Option 1 | Question Option 2 |
|------|-------------------|-------------------|
| **Demo 1 (Tech)** | "What are key differences between React and Vue?" | "What should I know about machine learning basics?" |
| **Demo 2 (Travel)** | "What are the best Greek islands to visit in summer?" | "What should I know before traveling to Greece?" |

---

## ‚úÖ Recording Checklist

- [ ] Ollama running (or fallback ready)
- [ ] Dev server running at localhost:3001
- [ ] Browser zoomed to 150%
- [ ] DevTools open (Network + Console)
- [ ] Screen recording software ready
- [ ] **Record Demo 1: Tech topic**
  - [ ] Ask question
  - [ ] Show prefetching in DevTools
  - [ ] Click top suggestion (instant)
  - [ ] Ask same question (instant cache hit)
- [ ] **Refresh page**
- [ ] **Record Demo 2: Travel topic**
  - [ ] Ask Greek islands question
  - [ ] Show suggestions are contextual (different from Demo 1!)
  - [ ] Show prefetching
  - [ ] Click suggestion (instant)
- [ ] Export as MP4
- [ ] Test playback

**You're ready to record!** üé¨
